{
  "cells": [
    {
      "metadata": {
        "_uuid": "a25dad79d0e0ac40da4ab1ffa5bf3e24008ca367"
      },
      "cell_type": "markdown",
      "source": "# Household Features Engineering\n\n\n"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "input_dir = '../input/'\nworking_dir = '../working/'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9632d88df34a7b6eed6332ca307520251a697eb0"
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6d041cc6d400253f8d3cc705f8d5c4497a6f4d6d",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(os.path.join(input_dir, 'train.csv'))\ntest = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n\n# Set index\ntrain.index = train['Id'].values\ntest.index = test['Id'].values\n\n# Pick Target\ntrain_target = train['Target']\n\n# Union train and test\nall_data = pd.concat([train.drop('Target', axis=1), test], axis=0)\n\nprint(train.shape)\nprint(test.shape)\nprint(all_data.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75c11ded696310ea36bf203b715f29209f85aa26"
      },
      "cell_type": "code",
      "source": "# data cleaning\n# copy from https://www.kaggle.com/katacs/data-cleaning-and-random-forest\n# and make a change it\ndef data_cleaning(data):\n    data['dependency']=np.sqrt(data['SQBdependency'])\n#     data['rez_esc']=data['rez_esc'].fillna(0)\n    data['v18q1']=data['v18q1'].fillna(0)\n    data['v2a1']=data['v2a1'].fillna(0)\n    \n    data['edjefa'] = data['edjefa'].replace({'no': 0, 'yes': 1})\n    data['edjefa'] = data['edjefa'].astype('int')\n    data['edjefe'] = data['edjefe'].replace({'no': 0, 'yes': 1})\n    data['edjefe'] = data['edjefe'].astype('int')\n    meaneduc_nan=data[data['meaneduc'].isnull()][['Id','idhogar','escolari']]\n    me=meaneduc_nan.groupby('idhogar')['escolari'].mean().reset_index()\n    for row in meaneduc_nan.iterrows():\n        idx=row[0]\n        idhogar=row[1]['idhogar']\n        m=me[me['idhogar']==idhogar]['escolari'].tolist()[0]\n        data.at[idx, 'meaneduc']=m\n        data.at[idx, 'SQBmeaned']=m*m\n        \n    return data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df5e868f140eceff0c6b9af50254b0f1d24ce84b"
      },
      "cell_type": "code",
      "source": "# train = data_cleaning(train)\n# test = data_cleaning(test)\nall_data = data_cleaning(all_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4f45c1b8d27f699eb1eac3cd8d05a6dd84db46d"
      },
      "cell_type": "code",
      "source": "# Tranform One-hot variables into Categorical variables\ndef onehot2cat(data, cat_col_new, cat_col_olds):\n    cat_col = data[cat_col_olds].idxmax(1)\n    cat_col.name = cat_col_new\n    cat_col = cat_col.astype('category')\n    data = pd.concat([data, cat_col], axis=1)\n    data = data.drop(cat_col_olds, axis=1)\n    return data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5693abf24771f907974986c3fc22866ab21a1588"
      },
      "cell_type": "code",
      "source": "cat_col_new_list = ['pared', 'piso', 'techo', 'abastagua', 'sanitario',\n                'energcocinar', 'elimbasu', 'estadocivil',\n                'parentesco', 'tipovivi', 'lugar', 'area']\ncat_col_dict = {}\nfor cat_col_new in cat_col_new_list:\n    cat_col_olds = [s for s in train.columns.tolist() if s.startswith(cat_col_new)]\n    cat_col_dict[cat_col_new] = cat_col_olds\n    \ncat_col_dict['electricity'] = ['public', 'planpri', 'noelec', 'coopele']\ncat_col_dict['sex'] = ['male', 'female']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f757cd047fa39ffddba8feaaaf99e1d3f37854eb"
      },
      "cell_type": "code",
      "source": "for cat_col_new, cat_col_olds in cat_col_dict.items():\n    print(cat_col_olds)\n#     train = onehot2cat(train, cat_col_new, cat_col_olds)\n#     test = onehot2cat(test, cat_col_new, cat_col_olds)\n    all_data = onehot2cat(all_data, cat_col_new, cat_col_olds)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24b29b1875e7ba44bc77e79bb227425fb25a46cf"
      },
      "cell_type": "code",
      "source": "# Encode one-hot variables into numeric\n# like (bad, regular, good) -> (0 ,1, 2)\ndef onehot2num(data, status_col_new, status_col_olds):\n    status_df = data[status_col_olds]\n    status_df.columns = list(range(len(status_col_olds)))\n    num_col = status_df.idxmax(1)\n    num_col.name = status_col_new\n    data = pd.concat([data, num_col], axis=1)\n    data = data.drop(status_col_olds, axis=1)\n    return data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "736fb171f7acf83c7b457dbd825b234dde0bc2b8"
      },
      "cell_type": "code",
      "source": "status_col_new_list = ['epared', 'etecho', 'eviv', 'instlevel']\nstatus_col_dict = {}\nfor status_col_new in status_col_new_list:\n    status_col_olds = [s for s in train.columns.tolist() if s.startswith(status_col_new)]\n    status_col_dict[status_col_new] = status_col_olds",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d6c8aaf162b3babb766d29ed38d7f85278abcd84"
      },
      "cell_type": "code",
      "source": "for status_col_new, status_col_olds in status_col_dict.items():\n    print(status_col_olds)\n#     train = onehot2num(train, status_col_new, status_col_olds)\n#     test = onehot2num(test, status_col_new, status_col_olds)\n    all_data = onehot2num(all_data, status_col_new, status_col_olds)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f9a9ca4f46c2a659fe15c2e444b496b015bf074"
      },
      "cell_type": "code",
      "source": "# Delete needless columns\nneedless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n                 'mobilephone']\nSQB_cols = [s for s in train.columns.tolist() if 'SQB' in s]\nneedless_cols.extend(SQB_cols)\n# train = train.drop(needless_cols, axis=1)\n# test = test.drop(needless_cols, axis=1)\nall_data = all_data.drop(needless_cols, axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b491892f67d35412857245b2430818ba301d5559"
      },
      "cell_type": "code",
      "source": "# Encode overcrowdig variables into crowding rate\nall_data['hacdor_rate'] = all_data['hogar_total'] / all_data['bedrooms']\nall_data['hacapo_rate'] = all_data['hogar_total'] / all_data['rooms']\nall_data = all_data.drop(['hacdor', 'hacapo'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fc6bc04cf22047e03e16f3f384612fc193288f3a"
      },
      "cell_type": "code",
      "source": "# Encode dummy variables into category type\ndummy_col_list = ['cielorazo', 'dis', 'computer', 'television']\nfor dummy_col in dummy_col_list:\n#     train[dummy_col] = train[dummy_col].astype('category')\n#     test[dummy_col] = test[dummy_col].astype('category')\n    all_data[dummy_col] = all_data[dummy_col].astype('category')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e4250bde94328d69b6bd1c9c8fcf8bdc9caa862"
      },
      "cell_type": "code",
      "source": "all_data.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0bb5ed86aaf82e71dabc79424acd2bfe18b6a294"
      },
      "cell_type": "markdown",
      "source": "## Aggregate household variables"
    },
    {
      "metadata": {
        "_uuid": "2941d9db5ce83eefe5134bd93eea613e68a5effe"
      },
      "cell_type": "markdown",
      "source": "大人の平均や子供の平均を取るとき、その世帯に大人あるいは子供がいない場合、値はNULLにする。"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a278bdb6cf5999750f884a1e526385473c7278cd"
      },
      "cell_type": "code",
      "source": "adult_data = all_data.query('age>18')\nchild_data = all_data.query('age<=18')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f7f749f9e66f26970992b3bb478ae945ed590cf"
      },
      "cell_type": "code",
      "source": "# DataFrameとカラム名が来たら、idhogarでgroupbyして、そのカラムの平均、分散、最小値などを一括で出力する関数\n\ndef agg_hogar(df, df_name, col):\n    df_g = df.groupby('idhogar')[col]\n    \n    df_g_mean = df_g.mean()\n    df_g_std =  df_g.std()\n    df_g_min = df_g.min()\n    df_g_median = df_g.median()\n    df_g_max = df_g.max()\n    df_g_range = df_g_max - df_g_min\n    \n    df_g_agg = pd.concat([df_g_mean,\n                          df_g_std,\n                          df_g_min,\n                          df_g_median,\n                          df_g_max,\n                          df_g_range],\n                         axis=1)\n    \n    agg_names = ['mean', 'std', 'min', 'median', 'max', 'range']\n    col_names = []\n    for agg_name in agg_names:\n        col_name = df_name + '_' + col + '_' + agg_name\n        col_names.append(col_name)\n    df_g_agg.columns = col_names\n    \n    return df_g_agg",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9fc808979047fe27dedd59ec3e72ae2e90512765"
      },
      "cell_type": "code",
      "source": "agg_dt_col_dict = {\n    'all'  : ['age', 'rez_esc'],\n    'adult': ['age', 'escolari', 'instlevel'],\n    'child': ['age', 'rez_esc']\n}\n\nagg_dt_dict = {\n    'all'  : all_data,\n    'adult': adult_data,\n    'child': child_data\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa654d9211476cc9b0b8af01cc01399c26b479fe"
      },
      "cell_type": "code",
      "source": "hogar_data = all_data.groupby('idhogar')['idhogar'].head(1)\nhogar_data.index = hogar_data\n\nfor key, cols_list_to_agg in agg_dt_col_dict.items():\n    df = agg_dt_dict[key]\n    for col in cols_list_to_agg:\n        hogar_data = pd.concat([hogar_data, agg_hogar(df, key, col)], axis=1, sort=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8bd8932762ffcac40be4cbe6bd967a8e16d00763"
      },
      "cell_type": "code",
      "source": "hogar_data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd08bf2458d052800fe8f671e3cfda2d2a9b80d8"
      },
      "cell_type": "markdown",
      "source": "* 大人の男女比率\n* 家族人数"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "541a198dfc3315e6bce6183969998ae4afe65707"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d12db2337c7e06d18223d9dbfb6f249e64a12fd6"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "55b0e86aa4c10b87aea29e461aac91e5dafe8486"
      },
      "cell_type": "markdown",
      "source": "## Rent Prediction\n### Extract heads of household and tipovivi==3(Room for rent)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7a7790f7240d3ef1800f9fd1575c5bf300e3284"
      },
      "cell_type": "code",
      "source": "hh_data = all_data[all_data['parentesco']=='parentesco1']\nrent_data = hh_data[hh_data['tipovivi']=='tipovivi3']\nrent_data.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b9088544eb6801a431c8b33e22a1407c05b49859"
      },
      "cell_type": "markdown",
      "source": "## Pick up columns related to dwellings"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b62b241b3f3001e375bee3d64da86f6321d2cfa"
      },
      "cell_type": "code",
      "source": "rent_df_col_list = ['v2a1', 'rooms', 'cielorazo', 'idhogar',\n                     'bedrooms', 'pared', 'piso', 'techo',\n                     'abastagua', 'sanitario', 'energcocinar',\n                     'elimbasu', 'lugar', 'area',\n                     'electricity', 'epared', 'etecho', 'eviv']\n\nrent_df = rent_data[rent_df_col_list]\n\nrent_idhogar = rent_df['idhogar']\nrent_y = rent_df['v2a1']\nrent_X = rent_df.drop(['idhogar', 'v2a1'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d1178f123c6c5a77d2533e20f1d9568700b02f9"
      },
      "cell_type": "code",
      "source": "params = {'num_leaves': 9, 'min_data_in_leaf': 4, 'max_depth': 6}\ngbm = lgb.LGBMRegressor(boosting_type='dart', objective='regression', random_state=0)\ngbm.set_params(**params)\ngbm.fit(rent_X, rent_y)\npred_rent = gbm.predict(all_data[rent_df_col_list].drop(['idhogar', 'v2a1'], axis=1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cf976c03d25d41b8ea09160786fd4db5048743e2"
      },
      "cell_type": "markdown",
      "source": "## Simple LightGBM"
    },
    {
      "metadata": {
        "_uuid": "1099afc2a2baa567d40ae83625ea29772b91deb0"
      },
      "cell_type": "markdown",
      "source": "### Merge features"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "182d75178f265c3797a99d770bd9ad7cc3edf43f"
      },
      "cell_type": "code",
      "source": "# rent prediction\nall_data['pred_rent'] = pred_rent\n\n# aggregated household features\nall_data = pd.merge(all_data, hogar_data, on='idhogar', how='left')\nall_data.set_index('Id', drop=False, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79581a974385c1b8e88843b7e8ab18e9dc6cb854"
      },
      "cell_type": "code",
      "source": "train = all_data.loc[train.index]\ntrain['Target'] = train_target\ntrain = train[train['parentesco']=='parentesco1']\ntrain = train.drop('parentesco', axis=1)\n\ntest = all_data.loc[test.index]\ntest = test.drop('parentesco', axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d60bc2fc0b86b1c935865dea92c3a5f874f1d64",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# Split data\ntrain_Id = train['Id'] # individual ID\ntrain_idhogar = train['idhogar'] # household ID\ntrain_y = train['Target'] # Target value\ntrain_X = train.drop(['Id', 'Target', 'idhogar'], axis=1) # features\n\ntest_Id = test['Id'] # individual ID\ntest_idhogar = test['idhogar'] # household ID\ntest_X = test.drop(['Id', 'idhogar'], axis=1) # features\n\n# Union train and test\n# all_Id = pd.concat([train_Id, test_Id], axis=0, sort=False)\n# all_idhogar = pd.concat([train_idhogar, test_idhogar], axis=0, sort=False)\n# all_X = pd.concat([train_X, test_X], axis=0, sort=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fabc3cfef991237f01fa3d85492531bfb75812fc"
      },
      "cell_type": "code",
      "source": "def evaluate_macroF1_lgb(truth, predictions):  \n    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n    f1 = f1_score(truth, pred_labels, average='macro')\n    return ('macroF1', f1, True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ddc14d963f2d16e376f15d50557b848d0f9fd2ec",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, f1_score, make_scorer\nimport lightgbm as lgb\n\nX_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.1, random_state=0)\n\nF1_scorer = make_scorer(f1_score, greater_is_better=True, average='macro')\n\nfit_params={\n    \"early_stopping_rounds\":30,\n    \"eval_metric\" : evaluate_macroF1_lgb, \n    \"eval_set\" : [(X_train,y_train), (X_test,y_test)],\n    'eval_names': ['train', 'valid'],\n#     'verbose': False,\n    'categorical_feature': 'auto'\n}\ngbm_param = {\n    'num_leaves':[14]\n    ,'min_data_in_leaf':[13]\n    ,'max_depth':[7]\n}\ngbm = GridSearchCV(\n    lgb.LGBMClassifier(objective='multiclassova', boosting_type='dart', class_weight='balanced', seed=0)\n    , gbm_param\n    , scoring=F1_scorer\n#     , fit_params=fit_params\n    , cv=3\n)\n\n\n# params = {'num_leaves': 14, 'min_data_in_leaf': 13, 'max_depth': 7, 'learning_rate': 0.09, 'feature_fraction': 0.74}\n# fit_params = {\"early_stopping_rounds\": 30, \"eval_set\": [[X_test, y_test]]}\n# gbm = lgb.LGBMClassifier(objective='multiclassova', boosting_type='dart', class_weight='balanced', random_state=0)\n# gbm.set_params(**params)\n\ngbm.fit(X_train, y_train, **fit_params)\n# gbm.best_params_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b6686e71c65137a5c9dfcb19aae96a8e08812d95"
      },
      "cell_type": "code",
      "source": "train_y.unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fca89a6d3c8db6d81c47affb23117203d78a334c"
      },
      "cell_type": "code",
      "source": "feature_imp = pd.DataFrame({\n    'features'  : X_train.columns,\n    'importance': gbm.feature_importances_\n    },\n    index=X_train.columns)\nfeature_imp.sort_values('importance', ascending=False, inplace=True)\n# feature_imp.sort_values('importance', ascending=False).plot(kind='bar')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aebf92306f1fc719a1c69aefced564be4790f30a"
      },
      "cell_type": "code",
      "source": "fig, ax = plt.subplots(figsize=(15, 5))\nax.bar(feature_imp['features'], feature_imp['importance'])\nplt.xticks(rotation=90)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "458423a2b5c5151f1fb397c98cf3f2cc6a6d251a"
      },
      "cell_type": "code",
      "source": "import pickle\nwith open(os.path.join(working_dir, '20180901_lgbm_rent_agg_hogar.pickle'), mode='wb') as f:\n    pickle.dump(gbm, f)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e133dcb8f8c1eadf0503e3c5338c09fe89ce449"
      },
      "cell_type": "code",
      "source": "y_test_pred = gbm.predict(X_test)\ncm = confusion_matrix(y_test, y_test_pred)\ncm_df_columns = ['pred_'+str(i) for i in range(cm.shape[0])]\ncm_df_index = ['true_'+str(i) for i in range(cm.shape[0])]\ncm_df = pd.DataFrame(data=cm, columns=cm_df_columns, index=cm_df_index)\nf1 = f1_score(y_test, y_test_pred, average='macro')\nprint(\"confusion matrix: \\n\", cm_df)\nprint(\"macro F1 score: \\n\", f1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4cf36dc0a7f27dd680725f948d0ff809cbf07b49"
      },
      "cell_type": "code",
      "source": "gbm = lgb.LGBMClassifier(objective='multiclassova', class_weight='balanced', random_state=0)\ngbm.set_params(**params)\ngbm.fit(train_X, train_y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e25bb77387bb8c9773930f3f06871bdd70413d0"
      },
      "cell_type": "code",
      "source": "pred = gbm.predict(test_X)\npred = pd.Series(data=pred, index=test_Id.values, name='Target')\npred = pd.concat([test_Id, pred], axis=1, join_axes=[test_Id.index])\npred.to_csv('20180901_lgbm_rent_agg_hogar.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5599ec9c4675841a86a980de352dbb4792ff652e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}